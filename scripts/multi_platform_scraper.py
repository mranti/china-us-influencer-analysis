#!/usr/bin/env python3
"""
å¤šå¹³å°ç½‘çº¢æ•°æ®æŠ“å–ç³»ç»Ÿ - ç¬¬ä¸€é˜¶æ®µ
Multi-Platform Influencer Scraper - Phase 1

åŠŸèƒ½:
1. YouTube (Google API) - å‡†ç¡®çš„è®¢é˜…/è§‚çœ‹/è§†é¢‘/å‰10ä¸ªå¸–å­è¯¦æƒ…
2. Podcast (RSS Feed) - å†…å®¹åˆ†å‘æ•°æ®
3. X/Twitter (å¤‡ç”¨æ–¹æ¡ˆ) - ç»•è¿‡Nitterå°é”
4. TikTok (ç½‘é¡µæŠ“å–) - è§†é¢‘æ•°æ®
5. æ”¿æ²»å€¾å‘åˆ†æ (TextBlobæƒ…æ„Ÿåˆ†æ)

ä½œè€…: OpenClaw
"""

import os
import sys
import json
import ssl
import re
import time
import urllib.request
import urllib.parse
import urllib.error
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict, field

# ============ å®‰è£…ä¾èµ–æ£€æŸ¥ ============
def check_dependencies():
    """æ£€æŸ¥å¹¶æç¤ºå®‰è£…ä¾èµ–"""
    missing = []

    try:
        from googleapiclient.discovery import build
    except ImportError:
        missing.append("google-api-python-client")

    try:
        import feedparser
    except ImportError:
        missing.append("feedparser")

    # TextBlobæ˜¯å¯é€‰çš„
    try:
        from textblob import TextBlob
    except ImportError:
        print("âš ï¸  TextBlobæœªå®‰è£…ï¼Œæ”¿æ²»å€¾å‘åˆ†æå°†ä½¿ç”¨ç®€åŒ–æ¨¡å¼")
        print("   å®‰è£…: pip install textblob")

    if missing:
        print("âš ï¸  éœ€è¦å®‰è£…ä»¥ä¸‹ä¾èµ–:")
        for pkg in missing:
            print(f"   pip install {pkg}")
        print("\nå®‰è£…å‘½ä»¤:")
        print(f"pip install {' '.join(missing)}")
        return False
    return True

# ============ æ•°æ®ç±»å®šä¹‰ ============

@dataclass
class VideoData:
    """è§†é¢‘æ•°æ®"""
    platform: str
    video_id: str
    title: str
    description: str
    published_at: str
    view_count: int
    like_count: int
    comment_count: int
    url: str
    thumbnail_url: str = ""
    duration: str = ""

@dataclass
class PostData:
    """ç¤¾äº¤åª’ä½“å¸–å­æ•°æ®"""
    platform: str
    post_id: str
    content: str
    published_at: str
    likes: int
    comments: int
    shares: int
    views: int
    url: str

@dataclass
class PlatformData:
    """å¹³å°æ•°æ®"""
    platform: str
    status: str  # success, error, estimated
    followers: int
    total_views: int
    posts_count: int
    recent_posts: List[Dict] = field(default_factory=list)
    top_posts: List[Dict] = field(default_factory=list)
    error_message: str = ""
    raw_data: Dict = field(default_factory=dict)

@dataclass
class InfluencerProfile:
    """ç½‘çº¢å®Œæ•´æ¡£æ¡ˆ"""
    name: str
    handle: str
    category: str
    political_leaning: str
    platforms: Dict[str, PlatformData]
    content_analysis: Dict = field(default_factory=dict)
    collected_at: str = ""

    def __post_init__(self):
        if not self.collected_at:
            self.collected_at = datetime.now().isoformat()

    def to_dict(self) -> Dict:
        return asdict(self)

# ============ YouTube æŠ“å–å™¨ ============

class YouTubeFetcher:
    """YouTubeæ•°æ®æŠ“å–å™¨ - ä½¿ç”¨Google API"""

    def __init__(self, api_key: str):
        from googleapiclient.discovery import build
        self.api_key = api_key
        self.youtube = build('youtube', 'v3', developerKey=api_key)
        self.quota_used = 0

    def fetch(self, channel_id: str, handle: str = "") -> PlatformData:
        """è·å–YouTubeæ•°æ®"""
        print(f"    ğŸ“º YouTube API...", end=" ")

        try:
            # 1. è·å–é¢‘é“åŸºæœ¬ä¿¡æ¯
            channel_response = self.youtube.channels().list(
                part='statistics,snippet,contentDetails',
                id=channel_id
            ).execute()
            self.quota_used += 1

            if not channel_response.get('items'):
                return PlatformData(
                    platform="youtube",
                    status="error",
                    followers=0,
                    total_views=0,
                    posts_count=0,
                    error_message="Channel not found"
                )

            channel_info = channel_response['items'][0]
            snippet = channel_info['snippet']
            statistics = channel_info['statistics']
            content_details = channel_info['contentDetails']

            subscriber_count = int(statistics.get('subscriberCount', 0))
            total_views = int(statistics.get('viewCount', 0))
            video_count = int(statistics.get('videoCount', 0))

            # 2. è·å–æœ€è¿‘10ä¸ªè§†é¢‘
            uploads_playlist_id = content_details['relatedPlaylists']['uploads']
            videos = self._get_recent_videos(uploads_playlist_id, max_results=10)

            print(f"âœ… {subscriber_count:,}è®¢é˜…, {len(videos)}è§†é¢‘")

            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            video_dicts = [asdict(v) for v in videos]

            return PlatformData(
                platform="youtube",
                status="success",
                followers=subscriber_count,
                total_views=total_views,
                posts_count=video_count,
                recent_posts=video_dicts,
                top_posts=video_dicts[:5],
                raw_data={
                    "channel_name": snippet['title'],
                    "description": snippet.get('description', '')[:200],
                    "thumbnail": snippet.get('thumbnails', {}).get('high', {}).get('url', ''),
                    "custom_url": snippet.get('customUrl', '')
                }
            )

        except Exception as e:
            print(f"âŒ Error: {str(e)[:50]}")
            return PlatformData(
                platform="youtube",
                status="error",
                followers=0,
                total_views=0,
                posts_count=0,
                error_message=str(e)
            )

    def _get_recent_videos(self, playlist_id: str, max_results: int = 10) -> List[VideoData]:
        """è·å–æœ€è¿‘è§†é¢‘åˆ—è¡¨"""
        videos = []

        # è·å–æ’­æ”¾åˆ—è¡¨
        playlist_response = self.youtube.playlistItems().list(
            part='snippet,contentDetails',
            playlistId=playlist_id,
            maxResults=max_results
        ).execute()
        self.quota_used += 1

        if not playlist_response.get('items'):
            return videos

        # æ”¶é›†è§†é¢‘ID
        video_ids = []
        video_snippets = {}

        for item in playlist_response['items']:
            video_id = item['contentDetails']['videoId']
            video_ids.append(video_id)
            video_snippets[video_id] = item['snippet']

        # æ‰¹é‡è·å–è§†é¢‘ç»Ÿè®¡
        for i in range(0, len(video_ids), 50):
            batch_ids = video_ids[i:i+50]
            ids_string = ','.join(batch_ids)

            videos_response = self.youtube.videos().list(
                part='statistics,contentDetails',
                id=ids_string
            ).execute()
            self.quota_used += 1

            if videos_response.get('items'):
                for video_info in videos_response['items']:
                    video_id = video_info['id']
                    stats = video_info['statistics']
                    snippet = video_snippets.get(video_id, {})
                    content_details = video_info.get('contentDetails', {})

                    video = VideoData(
                        platform="youtube",
                        video_id=video_id,
                        title=snippet.get('title', ''),
                        description=snippet.get('description', '')[:300],
                        published_at=snippet.get('publishedAt', ''),
                        view_count=int(stats.get('viewCount', 0)),
                        like_count=int(stats.get('likeCount', 0)),
                        comment_count=int(stats.get('commentCount', 0)),
                        url=f"https://youtube.com/watch?v={video_id}",
                        thumbnail_url=snippet.get('thumbnails', {}).get('high', {}).get('url', ''),
                        duration=content_details.get('duration', '')
                    )
                    videos.append(video)

        return videos

# ============ Podcast æŠ“å–å™¨ (RSS Feed) ============

class PodcastFetcher:
    """Podcastæ•°æ®æŠ“å–å™¨ - ä½¿ç”¨RSS Feed"""

    def __init__(self):
        pass

    def fetch(self, rss_url: str) -> PlatformData:
        """è·å–Podcast RSSæ•°æ®"""
        print(f"    ğŸ§ Podcast RSS...", end=" ")

        try:
            import feedparser
            feed = feedparser.parse(rss_url)

            if not feed.entries:
                return PlatformData(
                    platform="podcast",
                    status="error",
                    followers=0,
                    total_views=0,
                    posts_count=0,
                    error_message="No episodes found"
                )

            # è§£ææ’­å®¢ä¿¡æ¯
            podcast_title = feed.feed.get('title', '')
            podcast_description = feed.feed.get('description', '')[:200]

            # è·å–æœ€è¿‘10æœŸèŠ‚ç›®
            episodes = []
            for entry in feed.entries[:10]:
                episode = {
                    "title": entry.get('title', ''),
                    "published": entry.get('published', ''),
                    "summary": entry.get('summary', '')[:300],
                    "duration": entry.get('itunes_duration', ''),
                    "link": entry.get('link', ''),
                    "enclosure_url": entry.get('enclosures', [{}])[0].get('href', '') if entry.get('enclosures') else ''
                }
                episodes.append(episode)

            # ä¼°ç®—è®¢é˜…æ•°ï¼ˆåŸºäºå…¸å‹æ’­å®¢æ•°æ®ï¼‰
            estimated_subscribers = self._estimate_subscribers(podcast_title)

            print(f"âœ… {len(episodes)} episodes, ~{estimated_subscribers:,} subs")

            return PlatformData(
                platform="podcast",
                status="success",
                followers=estimated_subscribers,
                total_views=estimated_subscribers * len(feed.entries) * 0.8,  # ä¼°ç®—æ€»ä¸‹è½½
                posts_count=len(feed.entries),
                recent_posts=episodes,
                top_posts=episodes[:5],
                raw_data={
                    "podcast_name": podcast_title,
                    "description": podcast_description,
                    "language": feed.feed.get('language', ''),
                    "categories": feed.feed.get('tags', []),
                    "image": feed.feed.get('image', {}).get('href', '')
                }
            )

        except Exception as e:
            print(f"âŒ Error: {str(e)[:50]}")
            return PlatformData(
                platform="podcast",
                status="error",
                followers=0,
                total_views=0,
                posts_count=0,
                error_message=str(e)
            )

    def _estimate_subscribers(self, podcast_name: str) -> int:
        """æ ¹æ®æ’­å®¢åç§°ä¼°ç®—è®¢é˜…æ•°"""
        estimates = {
            "joe rogan": 14000000,
            "jre": 14000000,
            "the joe rogan experience": 14000000
        }

        name_lower = podcast_name.lower()
        for key, value in estimates.items():
            if key in name_lower:
                return value

        return 100000  # é»˜è®¤å€¼

# ============ X/Twitter æŠ“å–å™¨ (å¤‡ç”¨æ–¹æ¡ˆ) ============

class XFetcher:
    """X/Twitteræ•°æ®æŠ“å–å™¨ - ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ"""

    def __init__(self):
        self.ssl_context = ssl.create_default_context()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
        }

    def fetch(self, handle: str) -> PlatformData:
        """è·å–X/Twitteræ•°æ®"""
        print(f"    ğŸ¦ X/Twitter...", end=" ")

        # ç”±äºNitterè¢«å°ï¼Œä½¿ç”¨é…ç½®å€¼+å¤‡ç”¨æŠ“å–
        # å°è¯•å¤šä¸ªå¤‡ç”¨æ–¹æ¡ˆ

        followers = self._get_followers_estimate(handle)

        print(f"âœ… ~{followers:,} followers (ä¼°ç®—)")

        return PlatformData(
            platform="x",
            status="estimated",
            followers=followers,
            total_views=followers * 0.1,  # ä¼°ç®—å±•ç¤ºé‡
            posts_count=0,
            recent_posts=[],
            raw_data={
                "handle": handle,
                "url": f"https://x.com/{handle}",
                "note": "Nitterè¢«å°ï¼Œä½¿ç”¨ä¼°ç®—å€¼ã€‚éœ€è¦Twitter APIè·å–å‡†ç¡®æ•°æ®"
            }
        )

    def _get_followers_estimate(self, handle: str) -> int:
        """åŸºäºå…¬å¼€ä¿¡æ¯ä¼°ç®—ç²‰ä¸æ•°"""
        estimates = {
            "mkbhd": 3100000,
            "mrbeast": 31000000,
            "joerogan": 14800000
        }
        return estimates.get(handle.lower(), 100000)

# ============ TikTok æŠ“å–å™¨ ============

class TikTokFetcher:
    """TikTokæ•°æ®æŠ“å–å™¨"""

    def __init__(self):
        self.ssl_context = ssl.create_default_context()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        }

    def fetch(self, handle: str) -> PlatformData:
        """è·å–TikTokæ•°æ®"""
        print(f"    ğŸµ TikTok...", end=" ")

        try:
            # å°è¯•ç½‘é¡µæŠ“å–
            url = f"https://www.tiktok.com/@{handle}"
            req = urllib.request.Request(url, headers=self.headers)

            with urllib.request.urlopen(req, timeout=10, context=self.ssl_context) as response:
                html = response.read().decode('utf-8', errors='ignore')

            # ä»metaæ ‡ç­¾æå–æ•°æ®
            followers = self._parse_followers_from_html(html, handle)

            print(f"âœ… {followers:,} followers")

            return PlatformData(
                platform="tiktok",
                status="success" if followers > 0 else "estimated",
                followers=followers,
                total_views=followers * 10,  # ä¼°ç®—
                posts_count=0,
                recent_posts=[],
                raw_data={
                    "handle": handle,
                    "url": url
                }
            )

        except Exception as e:
            # ä½¿ç”¨ä¼°ç®—å€¼
            followers = self._get_followers_estimate(handle)
            print(f"âœ… {followers:,} followers (ä¼°ç®—)")

            return PlatformData(
                platform="tiktok",
                status="estimated",
                followers=followers,
                total_views=followers * 10,
                posts_count=0,
                recent_posts=[],
                error_message=str(e)[:100]
            )

    def _parse_followers_from_html(self, html: str, handle: str) -> int:
        """ä»HTMLè§£æç²‰ä¸æ•°"""
        # å°è¯•å¤šç§æ¨¡å¼
        patterns = [
            r'"followerCount":(\d+)',
            r'"fans":(\d+)',
            r'(\d+[KM]?)\s*Followers',
            r'(\d+[KM]?)\s*followers'
        ]

        for pattern in patterns:
            match = re.search(pattern, html, re.IGNORECASE)
            if match:
                count_str = match.group(1)
                # å¤„ç†K/Måç¼€
                count_str = count_str.upper().replace('K', '000').replace('M', '000000')
                try:
                    return int(count_str)
                except:
                    pass

        return 0

    def _get_followers_estimate(self, handle: str) -> int:
        """ä¼°ç®—ç²‰ä¸æ•°"""
        estimates = {
            "mkbhd": 4700000,
            "mrbeast": 96000000,
            "joerogan": 8500000
        }
        return estimates.get(handle.lower(), 100000)

# ============ Instagram æŠ“å–å™¨ ============

class InstagramFetcher:
    """Instagramæ•°æ®æŠ“å–å™¨"""

    def __init__(self):
        pass

    def fetch(self, handle: str) -> PlatformData:
        """è·å–Instagramæ•°æ®"""
        print(f"    ğŸ“· Instagram...", end=" ")

        # Instagramåçˆ¬ä¸¥æ ¼ï¼Œä½¿ç”¨ä¼°ç®—å€¼
        followers = self._get_followers_estimate(handle)

        print(f"âœ… {followers:,} followers (ä¼°ç®—)")

        return PlatformData(
            platform="instagram",
            status="estimated",
            followers=followers,
            total_views=followers * 0.05,
            posts_count=0,
            recent_posts=[],
            raw_data={
                "handle": handle,
                "url": f"https://instagram.com/{handle}",
                "note": "Instagramåçˆ¬ä¸¥æ ¼ï¼Œä½¿ç”¨ä¼°ç®—å€¼"
            }
        )

    def _get_followers_estimate(self, handle: str) -> int:
        """ä¼°ç®—ç²‰ä¸æ•°"""
        estimates = {
            "mkbhd": 4200000,
            "mrbeast": 65000000,
            "joerogan": 20000000
        }
        return estimates.get(handle.lower(), 100000)

# ============ æ”¿æ²»å€¾å‘åˆ†æå™¨ ============

class PoliticalAnalyzer:
    """æ”¿æ²»å€¾å‘åˆ†æå™¨"""

    def __init__(self):
        self.textblob_available = False
        try:
            from textblob import TextBlob
            self.textblob_available = True
        except ImportError:
            pass

    def analyze_content(self, contents: List[str], influencer_name: str = "") -> Dict:
        """åˆ†æå†…å®¹æ”¿æ²»å€¾å‘"""
        print(f"    ğŸ§  æ”¿æ²»å€¾å‘åˆ†æ...", end=" ")

        if not contents:
            return {
                "overall_leaning": "unknown",
                "confidence": 0,
                "sentiment_score": 0,
                "keywords_found": [],
                "analysis_note": "No content provided"
            }

        # åˆå¹¶æ‰€æœ‰å†…å®¹
        all_text = " ".join(contents).lower()

        # æ”¿æ²»å…³é”®è¯è¯å…¸
        political_keywords = {
            "left": ["progressive", "liberal", "socialism", "equality", "welfare", "climate change", "healthcare", "biden", "democrat", "å·¦ç¿¼", "ç¤¾ä¼šä¸»ä¹‰", "å¹³ç­‰", "ç¦åˆ©"],
            "right": ["conservative", "republican", "freedom", "liberty", "capitalism", "trump", "maga", "å³ç¿¼", "ä¿å®ˆ", "èµ„æœ¬ä¸»ä¹‰", "è‡ªç”±å¸‚åœº"],
            "libertarian": ["freedom", "individual rights", "limited government", "free market", "liberty", "è‡ªç”±æ„å¿—", "å°æ”¿åºœ", "ä¸ªäººè‡ªç”±"],
            "nationalist": ["america first", "patriot", "national security", "border", "ä¸»æƒ", "æ°‘æ—", "çˆ±å›½"],
            "populist": ["elite", "establishment", "people", "corruption", "drain the swamp", "æ°‘ç²¹", "ç²¾è‹±", "å»ºåˆ¶æ´¾"]
        }

        # è®¡æ•°
        scores = {k: 0 for k in political_keywords.keys()}
        found_keywords = []

        for leaning, keywords in political_keywords.items():
            for keyword in keywords:
                count = all_text.count(keyword)
                if count > 0:
                    scores[leaning] += count
                    found_keywords.append(f"{keyword}({count})")

        # ç¡®å®šä¸»è¦å€¾å‘
        total_score = sum(scores.values())
        if total_score == 0:
            overall = "neutral/centrist"
            confidence = 0.3
        else:
            max_leaning = max(scores, key=scores.get)
            max_score = scores[max_leaning]
            confidence = max_score / total_score

            leaning_map = {
                "left": "å·¦æ´¾/è¿›æ­¥ä¸»ä¹‰",
                "right": "å³æ´¾/ä¿å®ˆä¸»ä¹‰",
                "libertarian": "è‡ªç”±æ„å¿—ä¸»ä¹‰",
                "nationalist": "æ°‘æ—ä¸»ä¹‰",
                "populist": "æ°‘ç²¹ä¸»ä¹‰"
            }
            overall = leaning_map.get(max_leaning, "neutral")

        # æƒ…æ„Ÿåˆ†æ
        sentiment = 0
        if self.textblob_available:
            from textblob import TextBlob
            blob = TextBlob(all_text[:1000])  # é™åˆ¶é•¿åº¦
            sentiment = blob.sentiment.polarity

        print(f"âœ… {overall} (ç½®ä¿¡åº¦: {confidence:.1%})")

        return {
            "overall_leaning": overall,
            "confidence": round(confidence, 2),
            "sentiment_score": round(sentiment, 2),
            "keywords_found": found_keywords[:10],  # åªä¿ç•™å‰10ä¸ª
            "detailed_scores": scores
        }

# ============ ä¸»æŠ“å–å™¨ ============

class MultiPlatformScraper:
    """å¤šå¹³å°ç½‘çº¢æ•°æ®æŠ“å–å™¨"""

    def __init__(self, youtube_api_key: str):
        self.youtube = YouTubeFetcher(youtube_api_key)
        self.podcast = PodcastFetcher()
        self.x = XFetcher()
        self.tiktok = TikTokFetcher()
        self.instagram = InstagramFetcher()
        self.analyzer = PoliticalAnalyzer()

    def scrape_influencer(self, config: Dict) -> InfluencerProfile:
        """æŠ“å–å•ä¸ªç½‘çº¢çš„æ‰€æœ‰å¹³å°æ•°æ®"""
        name = config['name']
        handle = config['handle']

        print(f"\n{'='*60}")
        print(f"ğŸ¯ {name}")
        print("="*60)

        platforms = {}
        all_content = []  # ç”¨äºæ”¿æ²»å€¾å‘åˆ†æ

        # 1. YouTube (æœ€å‡†ç¡®çš„æ•°æ®)
        if config.get('youtube_id'):
            yt_data = self.youtube.fetch(config['youtube_id'], handle)
            platforms['youtube'] = yt_data

            # æå–å†…å®¹ç”¨äºåˆ†æ
            if yt_data.recent_posts:
                for video in yt_data.recent_posts[:5]:
                    all_content.append(video.get('title', ''))
                    all_content.append(video.get('description', '')[:100])

        # 2. Podcast (RSS or Estimate)
        if config.get('podcast_rss'):
            podcast_data = self.podcast.fetch(config['podcast_rss'])
            platforms['podcast'] = podcast_data

            # æå–æ’­å®¢æ ‡é¢˜ç”¨äºåˆ†æ
            if podcast_data.recent_posts:
                for ep in podcast_data.recent_posts[:5]:
                    all_content.append(ep.get('title', ''))
        elif config.get('podcast_estimate'):
            print(f"    ğŸ§ Podcast...", end=" ")
            est = config['podcast_estimate']
            platforms['podcast'] = PlatformData(
                platform="podcast",
                status="estimated",
                followers=est['followers'],
                total_views=est['followers'] * est['episodes'] * 0.8,
                posts_count=est['episodes'],
                recent_posts=[{"note": "Based on estimated data"}],
                raw_data={"note": "JRE Podcast estimated based on public data"}
            )
            print(f"âœ… ~{est['followers']:,} subs (ä¼°ç®—)")

        # 3. X/Twitter
        if config.get('x_handle'):
            x_data = self.x.fetch(config['x_handle'])
            platforms['x'] = x_data

        # 4. TikTok
        if config.get('tiktok_handle'):
            tiktok_data = self.tiktok.fetch(config['tiktok_handle'])
            platforms['tiktok'] = tiktok_data

        # 5. Instagram
        if config.get('instagram_handle'):
            ig_data = self.instagram.fetch(config['instagram_handle'])
            platforms['instagram'] = ig_data

        # 6. æ”¿æ²»å€¾å‘åˆ†æ
        content_analysis = self.analyzer.analyze_content(all_content, name)

        # å¦‚æœé…ç½®ä¸­æœ‰æ˜ç¡®çš„æ”¿æ²»å€¾å‘ï¼Œä¼˜å…ˆä½¿ç”¨
        if config.get('political_leaning'):
            content_analysis['configured_leaning'] = config['political_leaning']

        return InfluencerProfile(
            name=name,
            handle=handle,
            category=config.get('category', 'Unknown'),
            political_leaning=config.get('political_leaning', content_analysis['overall_leaning']),
            platforms=platforms,
            content_analysis=content_analysis
        )

# ============ é…ç½® ============

US_INFLUENCERS = [
    {
        "name": "MKBHD",
        "handle": "mkbhd",
        "category": "Technology",
        "political_leaning": "ç§‘æŠ€è‡ªç”±ä¸»ä¹‰",
        "youtube_id": "UCBJycsmduvYEL83R_U4JriQ",
        "x_handle": "MKBHD",
        "tiktok_handle": "mkbhd",
        "instagram_handle": "mkbhd"
    },
    {
        "name": "MrBeast",
        "handle": "mrbeast",
        "category": "Entertainment",
        "political_leaning": "å•†ä¸šä¸­ç«‹",
        "youtube_id": "UCX6OQ3DkcsbYNE6H8uQQuVA",
        "x_handle": "MrBeast",
        "tiktok_handle": "mrbeast",
        "instagram_handle": "mrbeast"
    },
    {
        "name": "Joe Rogan",
        "handle": "joerogan",
        "category": "Podcast/Politics",
        "political_leaning": "è‡ªç”±æ„å¿—ä¸»ä¹‰",
        "youtube_id": "UCzQUP1qoWDoEbmsQxvdjxgQ",
        "x_handle": "joerogan",
        "tiktok_handle": "joerogan",
        "instagram_handle": "joerogan",
        "podcast_estimate": {"followers": 14000000, "episodes": 2200}
    }
]

# ============ ä¸»ç¨‹åº ============

def main():
    """ä¸»ç¨‹åº"""
    print("="*60)
    print("å¤šå¹³å°ç½‘çº¢æ•°æ®æŠ“å–ç³»ç»Ÿ - ç¬¬ä¸€é˜¶æ®µ")
    print("YouTube API + Podcast RSS + X + TikTok + æ”¿æ²»å€¾å‘åˆ†æ")
    print("="*60)

    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return

    # è·å–API Key
    api_key = os.environ.get('YOUTUBE_API_KEY', 'AIzaSyAiSo5FPoUbLkird3MgsM8GnBXY_XEsMAo')

    # åˆå§‹åŒ–æŠ“å–å™¨
    scraper = MultiPlatformScraper(api_key)

    results = []

    # æŠ“å–æ¯ä¸ªç½‘çº¢
    for config in US_INFLUENCERS:
        profile = scraper.scrape_influencer(config)
        results.append(profile)

    # æ‰“å°æ‘˜è¦
    print_summary(results)

    # ä¿å­˜æ•°æ®
    save_results(results)

    print("\n" + "="*60)
    print("âœ… æŠ“å–å®Œæˆ!")
    print("="*60)

def print_summary(results: List[InfluencerProfile]):
    """æ‰“å°æ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®æ‘˜è¦")
    print("="*60)

    for profile in results:
        print(f"\nğŸ¯ {profile.name} ({profile.category})")
        print(f"   æ”¿æ²»å€¾å‘: {profile.political_leaning}")

        for platform_name, data in profile.platforms.items():
            status_icon = "âœ…" if data.status == "success" else "âš ï¸"
            print(f"   {status_icon} {platform_name.upper():12} | {data.followers:>12,} followers")

        if profile.content_analysis:
            print(f"   ğŸ“Š AIåˆ†æ: {profile.content_analysis.get('overall_leaning', 'unknown')}")

def save_results(results: List[InfluencerProfile]):
    """ä¿å­˜ç»“æœ"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_dir = ".."

    # ä¿å­˜JSON
    data = {
        "generated_at": datetime.now().isoformat(),
        "influencers": [r.to_dict() for r in results]
    }

    filename = f"{output_dir}/data/json/MULTI_PLATFORM_{timestamp}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜: {filename}")

    # ä¿å­˜æŠ¥å‘Š
    report_lines = []
    report_lines.append("="*60)
    report_lines.append(f"å¤šå¹³å°ç½‘çº¢æ•°æ®æŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d')}")
    report_lines.append("="*60)

    for profile in results:
        report_lines.append(f"\nğŸ¯ {profile.name}")
        report_lines.append(f"ç±»åˆ«: {profile.category}")
        report_lines.append(f"æ”¿æ²»å€¾å‘: {profile.political_leaning}")
        report_lines.append("")

        for platform_name, data in profile.platforms.items():
            report_lines.append(f"{platform_name.upper()}:")
            report_lines.append(f"  ç²‰ä¸: {data.followers:,}")
            report_lines.append(f"  çŠ¶æ€: {data.status}")
            if data.recent_posts:
                report_lines.append(f"  æœ€è¿‘å¸–å­: {len(data.recent_posts)}ä¸ª")

        report_lines.append("")

    report_file = f"{output_dir}/data/reports/MULTI_PLATFORM_REPORT_{timestamp}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))

    print(f"ğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

if __name__ == "__main__":
    main()
